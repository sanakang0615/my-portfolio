{
  "projects": [
    {
      "title": "Kyobo Life Insurance AI Chatbot",
      "type": "Web App",
      "description": "Description in progress",
      "role": "Project",
      "tags": ["MVP", "Web App", "Full-stack Development", "LLM", "ML Model"],
      "stack": ["NextJS", "Python", "FastAPI", "OpenAI", "Express", "FAISS"],
      "links": {}
    },
    {
      "title": "KAIST AI-Based Educational Environment Innovation Project",
      "type": "Web App",
      "description": "Selected as one of 11 teams in a university-wide initiative, managing a project with a budget of 9.6 million KRW.<br/> Leading the development of an AI-driven system for summarizing lab seminar Q&A and generating graphicalrepresentations through a human-centered HCI approach. <br/>Position: Team Lead<br/>",
      "role": "Project",
      "tags": ["MVP", "Web App", "Full-stack Development", "LLM"],
      "stack": ["NextJS", "LLM"],
      "links": {}
    },
    {
      "title": "AdOasis Marketing AI Analysis Generator",
      "type": "Web App",
      "description": "Description in progress",
      "role": "Project",
      "tags": ["MVP", "Web App", "Full-stack Development", "Design", "LLM"],
      "stack": ["NextJS", "Python", "FastAPI", "OpenAI"],
      "links": {}
    },
    {
      "title": "Smart Warehouse Management System",
      "type": "WMS",
      "description": "Description in progress",
      "role": "Project",
      "tags": ["Web App", "Mobile App", "Full-stack Development", "Design"],
      "stack": ["AWS", "ReactJS", "Android Studio"],
      "links": {}
    },
    {
      "title": "HdMedi MedExtractor",
      "type": "Library",
      "description": "# Overview\n\nHDMedi MedExtractor is designed to extract medication names from prescription and medicine bag images, mapping them to unique names registered with the Ministry of Food and Drug Safety, even if different names are used by different pharmacies.\n\n## Why HDMedi Extractor?\n\nExtracting Korean medication names from prescriptions or medicine bag images presents two challenges. First, identifying which text represents a medication name is difficult when reading image data through OCR. For instance, without training, can a computer recognize 'ÎßàÏù¥ÏïîÎ∂ÄÌÜ®Ï†úÌîºÏ†ïÏù¥' as a medication name? This issue arises due to the lack of a NER model specialized for Korean medication names. Second, different pharmacies may use different names for the same medication, necessitating standardization. Our team developed HDMedi Extractor to address these challenges.\n\n## Key Processes\n\n1. **Image Preprocessing**: Convert input images to text using Naver OCR, merging lines into sentences based on y-values.\n2. **Preprocessing and Line Removal**: Filter out lines unlikely to contain medication names from OCR-processed text.\n3. **Name Extraction and Alignment**: Extract medication names by comparing text with a medication name database, aligning different names for the same medication.\n\n## Requirements\n\n### Package Installation\n\nTo run this project, install the following packages: RxBagExtractor, numpy, pandas.\n\n```bash\npip install RxBagExtractor numpy pandas\n```\n\nRxBagExtractor is a preprocessing Python package developed by our team, available on PyPI.\n\n### Medication Name Database\n\nTo ensure consistency, we built a medication name database based on the Ministry of Food and Drug Safety's product approval information, accounting for different names used by pharmacies.\n\n## Function Call Order\n\n1. `get_ocr_image_to_element(image_path)`\n   - Calls `extractor(text)` from RxBagExtractor for text preprocessing and filtering.\n2. `process_text(text)`\n   - Calls `process_line(query)`\n   - Calls `preprocess_query(query)`\n     - Calls `extract_unit(query)`\n     - Calls `store_leftovers(match)` internally\n     - Calls `extract_chojungsung(c)` for Hangul decomposition\n   - Calls `find_best_match(line, medication_db, query_unit)`\n     - Calls `generate_ngrams(text, n=3)`\n     - Calls `hangul_edit_distance(word1, word2)`\n       - Calls `phoneme_distance(a, b, phoneme_groups)`\n         - Calls `get_phoneme_group(phoneme, phoneme_groups)`\n     - Calls `extract_unit(med)` again\n   - Reuses `extract_chojungsung(c)`\n\n## Key Function Descriptions\n\n### `extract_unit(text)`\n\nExtracts medication units from text with typos.\n\n**Return**: Tuple (result, leftovers)\n\n- `result`: Standardized unit string\n- `leftovers`: List of strings recognized as units\n\n### `generate_ngrams(text, n=3)`\n\nGenerates a list of n-gram substrings from input text.\n\n**Return**: List of substrings\n\n### `phoneme_distance(a, b, phoneme_groups)`\n\nCalculates distance between two phonemes considering phoneme groups.\n\n**Return**: Integer distance\n\n### `hangul_edit_distance(word1, word2)`\n\nCalculates similarity score between two words based on phoneme distance.\n\n**Return**: Integer distance\n\n### `find_best_match(line, medication_db, query_unit, threshold=4)`\n\nFinds the most similar medication name in the database to the given text.\n\n**Return**: Tuple (med_match, best_score)\n\n### `process_line(query)`\n\nPrepares input line and filters medication_db before calling `find_best_match`.\n\n### `process_text(text)`\n\nProcesses multiple text lines to return matched medication names.\n\n## Performance\n\nTested on approximately 60 medicine bag data, achieving:\n\n- Overall Precision: 0.655\n- Overall Recall: 0.728\n- Overall F1 Score: 0.690",
      "role": "Project",
      "tags": ["MVP", "Image Processing", "Machine Learning", "Computer Vision"],
      "stack": ["Python", "OpenCV", "OCR"],
      "period": "2025",
      "links": {},
      "images": ["/projects/RXExtractor.png"]
    },

    {
      "title": "Leveraging GraphSAGE for Location-Based Sales Analysis in F&B Franchises",
      "type": "ML Model",
      "description": "# Project Overview\n\nDeveloped a GraphSAGE-based sales prediction model for F&B franchises, reducing RMSE by 10.6% compared to manual expert predictions.\n\n# Implementation Details\n\nTo operationalize the model, I built a full-stack web service using React and FastAPI, allowing internal experts to easily access and interact with the results.\n\n# Responsibilities\n\nI was responsible for both the machine learning pipeline and the frontend interface, ensuring seamless integration between prediction logic and user experience.",
      "role": "ML Team Intern (SweetSpot Inc.)",
      "tags": ["Machine Learning", "Prediction Model", "Full-stack Development"],
      "stack": ["Python", "JavaScript", "React", "FastAPI", "GraphSAGE"],
      "period": "2024",
      "emoji": "üè¢",
      "links": { 

      },
      "images": []
    },
    {
      "title": "Comparative Topic Network Analysis: Pre-GPT Era vs. GPT Era Prompts",
      "type": "ML Model",
      "description": "",
      "role": "Project",
      "tags": ["Network Analysis", "NLP"],
      "stack": ["Python", "Gephi", "BERTopic"],
      "period": "2024",
      "links": { 

      },
      "emoji": "üìä",
      "images": []
    },
    {
      "title": "TransWeb3 Wiki Project",
      "type": "Blockchain",
      "description": "# Award Recognition\n\nüèÜ Received the Sponsor Prize by Polygon in **Ethcon 2023**, hosted by Ethereum Foundation.\n\n# Project Explanation\n\n**TransWeb3 Wiki Project** addresses a significant challenge within the web3 ecosystem ‚Äî the language barrier faced by approximately 95% of the global population who do not use English as their primary language. Our solution leverages the power of community-driven translations to enhance accessibility and foster broader adoption of web3 technologies. Contributors can participate by translating content, improving existing translations, and earning NFTs as a form of recognition and potential career advancement within the web3 space.\n\n# Connectable Wallet\n\nConnectable wallets include [MetaMask](https://metamask.io/), [Rainbow](https://rainbow.me/), and [Coinbase Wallet](https://www.coinbase.com/wallet).\n\n# Deployed Network\n\nThe project is deployed on multiple networks including Ethereum, Polygon, Linea Goerli Testnet, Sepolia Testnet, Polygon Mumbai Testnet, Polygon zkEVM Testnet, Taiko Grimsvotn L2, and Taiko Eldfell L3.",
      "role": "Project",
      "tags": ["Blockchain", "Web3", "Full-stack Development"],
      "stack": ["Next.js", "Express.js", "WalletConnect", "Hardhat", "Alchemy", "Sismo"],
      "period": "2023",
      "links": { 

      },
      "emoji": "üåê",
      "images": ["/projects/Blockchain-1.png", "/projects/Blockchain-2.png"]
    },
    {
      "title": "UniTasker for Remote Study",
      "type": "Mobile App",
      "description": "# Project Description\n\n**UniTasker** was developed to assist university students studying remotely during online classes. By entering their university, students can add courses offered, create task lists under those courses, and share progress checks with followers.\n\n# Service Features\n\n## 1. Login\n\nLogin through Kakao ID or sign up directly in the app. Accounts created with Kakao ID use Kakao tokens to generate a new encrypted JSON Web Token.\n\n## 2. Home Screen\n\nDisplays trending courses and users based on follower counts.\n\n## 3. Course Search\n\nSearch by course title or number. Top-followed courses appear on the home screen regardless of the school.\n\n## 4. View Tasks\n\nView and react to tasks posted by others enrolled in the same courses.\n\n## 5. Add and Review Tasks\n\nOrganize and manage tasks by course and date. Interact with tasks followed by users or those in the same courses.\n\n## 6. User Profile\n\nView follower count, number of followings, affiliated school, etc. Usernames and profile pictures are generated randomly.\n\n# Dependencies\n\n- Spring Boot, MyBatis, Spring Security, Validation, JWT for authentication and security\n- Redis for data management and caching\n- Webflux and Reactor for reactive programming\n- Swagger for API documentation\n- Gson for JSON processing\n- Lombok for boilerplate code reduction",
      "role": "Project",
      "tags": ["Mobile App"],
      "stack": ["Dart", "Flutter", "Spring Boot"],
      "period": "2021",
      "links": { 

      },
      "emoji": "‚òëÔ∏è",
      "images": ["/projects/UniTasker_3.png","/projects/UniTasker_1.png", "/projects/UniTasker_2.png"]
    },
    {
      "title": "AIDMS (An ID Management System based on Blockchain)",
      "type": "App Design",
      "description": "üèÜ Received the Grand Prize in the Arab-Korean Startup Pitch 2022",
      "role": "Project",
      "tags": ["Blockchain", "Web3", "Mobile App", "Design"],
      "stack": ["Flutter", "Figma"],
      "period": "2022",
      "links": { 
      },
      "emoji": "‚òëÔ∏è",
      "images": ["/projects/AIDMS.png"]
    },
    {
      "title": "VENETA Multi-Issuer Blockchain System",
      "type": "Blockchain",
      "description": "Designed and developed MVP for blockchain-based P2P trading system.\n\n- Selected for government-sponsored Financial Regulatory Sandbox\n- Implemented smart contracts for P2P trading\n- Filed patent for novel consensus mechanism",
      "role": "Intern (UWS Blockchain R&D Center)",
      "tags": ["MVP", "System Building", "Blockchain"],
      "stack": [ "Java", "JavaScript", "Solidity", "React", "Spring Boot","Smart Contract"],
      "period": "2022",
      "links": { 
      },
      "emoji": "‚õìÔ∏è",
      "images": ["/projects/Veneta.png"]
    },
    {
      "title": "Death's Word Chain Game",
      "type": "Web App",
      "description": "Interactive vocabulary learning game developed while studying GRE words.",
      "role": "Others",
      "tags": ["Web Development"],
      "stack": ["JavaScript", "Next"],
      "period": "2025",
      "links": { 
        "play": "wordchain.sanakang.xyz" 
      },
      "emoji": "üéÆ",
      "images": ["/projects/word-chain-1.png", "/projects/word-chain-2.png"]
    },
    {
      "title": "Detective Cell for #POTD",
      "type": "ML Model",
      "description": "**Detective Cell for #POTD Service** offers an innovative way to engage users by simulating interactions with characters from the popular webtoon \"Yumi's Cells.\"\n\nThis web service uses a dynamic chat-based interface to collect users' **facial and voice** inputs to recommend **locations** that suit their mood and personality for the picture of the day.",
      "role": "Game Developer",
      "tags": ["Web Development", "Machine Learning"],
      "stack": ["JavaScript", "Python", "Flask", "React", "Face shape classifier", "Voice analyzer"],
      "period": "2024",
      "links": { 
      },
      "emoji": "üîç",
      "images": ["/projects/OOPD.png"]
    },
    {
      "title": "Offline Shopping Aid Gloves for the Visually Impaired",
      "type":"3D Modeling",
      "description": "**Offline Shopping Aid Gloves for the Visually Impaired** Project addresses the significant challenges visually impaired people face during offline shopping due to the information accessibility gap. By focusing on sensory information processing, particularly visual cues which constitute 90% of the brain's input, our project aims to enhance shopping independence for visually impaired individuals.\n\n- The key innovation lies in specially designed gloves that assist with product recognition and navigation in stores. The gloves use built-in technology to provide auditory feedback about products, helping users identify items through barcode and color recognition features.\n- Addressing the lack of useful Braille on products, the gloves also aim to replace standard barcodes with Braille voice conversion codes, thus providing a practical solution to the real-world needs of the visually impaired.\n\n## Technical Specifications\n\n### 1. Right-Hand Glove Development for Color Identification and Product Classification\n\n#### 1.1 Implementation Goals and Components Used\n\nThe right-hand glove focuses on aiding visually impaired users by **providing color information of products**, which can be crucial for product differentiation. This glove utilizes an **RGB sensor** to detect the color of the item in hand and communicates this information through an auditory system powered by the **Arduino library Talkie**, converting color data into spoken words. This feature aims to assist in identifying and distinguishing products based on their color characteristics.\n\n#### 1.2 Construction and Functionality\n\nSimilar to the left-hand glove, the right-hand glove features tactile switches that trigger operations such as identifying and vocalizing colors. The glove was designed to perform under practical conditions, successfully identifying primary colors of widely known products. The glove's exterior was also crafted using AUTOCAD and printed via 3D printing technology at Idea Factory, ensuring that the design is both functional and accessible for users.\n\n### 2. Left-Hand Glove Development\n\n#### 2.1 Implementation Goals and Components Used\n\nThe left-hand glove is engineered to assist visually impaired individuals by enabling them to identify products through **barcode scanning**. The glove integrates a barcode reader to scan and decode product barcodes, which are prevalent on product displays and packaging. This technology helps in determining what product it is by reading the barcode assigned to each product. Initially, the product utilized speakers for audio feedback; however, due to limitations, buzzers were used as substitutes to convey the product information audibly.\n\n#### 2.2 Construction and Functionality\n\nUpon pressing a button on the barcode reader, the device **activates and emits light** to facilitate barcode recognition. The glove was **tested** in a controlled environment, distinguishing canned beverages like Coca-Cola, Pepsi, and Mountain Dew based on their barcodes, which had been pre-registered in our database. Future developments could see the system connecting to a server for real-time data updates, expanding its utility.\n\nThe glove's cover was **designed using AUTOCAD** and **produced with a 3D printer** from KAIST Idea Factory. Specific features of the glove include holes for scanner button access, sound emission, and velcro attachments for easy detachment and reattachment of the device.",
      "role": "Project",
      "tags": ["3D Printing", "Arduino Development"],
      "stack": ["Arduino", "AUTOCAD", "3D Printing"],
      "period": "2022",
      "links": { 
      },
      "emoji": "üîç",
      "images": ["/projects/ShoppingAid-1.png", "/projects/ShoppingAid-2.png", "/projects/ShoppingAid-3.png"]
    },
    {
      "title": "Fractional NFT Service",
      "type": "Blockchain",
      "description": "# Project Description\n\nThe **Fractional NFT Service** employs the Ethereum **ERC-1155 standard** for the fractional ownership of NFTs. It fundamentally transforms the digital ownership landscape by allowing the division of a single NFT into **multiple distinct fractions**, each uniquely owned and managed via smart contracts.\n\n# **Key Features**\n\n- **Fractional Ownership via ERC-1155**: The platform leverages the ERC-1155 standard, which permits the creation of multiple token types within a single contract, enabling each fraction to be a fully tradable and individually owned asset. These smart contracts manage the minting, trading, and ownership records of these fractions.\n- **NFT-Matrix Function:** Central to this platform is the innovative NFT-Matrix function, which allows for the complex fractionalization of NFTs. It divides an NFT into unique matrix-based fractions, each with a unique coordinate, enabling individual ownership of each segment.\n- **Decentralized Data Management:** Leveraging IPFS, the platform ensures decentralized and secure storage of all related data, including ownership records and transaction history, which supports the integrity and security of the fractional NFTs.",
      "role": "National G-Core Project (KAIST MIKES Lab)",
      "tags": ["NFT", "Blockchain", "Smart Contract", "Full-stack Development"],
      "stack": ["Solidity", "JavaScript", "Next"],
      "period": "2022",
      "links": { 
      },
      "emoji": "üîç",
      "images": ["/projects/FNFT.png"]
    },
    {
      "title": "Coca-Cola Price Prediction Project",
      "type": "ML Model",
      "description": "",
      "role": "Data & ML Team Intern (LG HnH)",
      "tags": ["Machine Learning", "Prediction Model", "Data Analysis"],
      "stack": ["Phython", "ML Model", "Streamlit"],
      "period": "2021",
      "links": { 
      },
      "emoji": "üîç",
      "images": ["/projects/LGHnH.png"]
    },
    {
      "title": "Inventory Management Web App",
      "type": "Web App",
      "description": "",
      "role": "Data & ML Team Intern (LG HnH)",
      "tags": ["Web Development", "Data Analysis"],
      "stack": ["Phython", "Streamlit"],
      "period": "2021",
      "links": { 
      },
      "emoji": "üîç",
      "images": ["/projects/LGHnH.png"]
    },
    {
      "title": "Shuffle & Discover",
      "type": "Mobile App",
      "description": "",
      "role": "",
      "tags": ["Mobile App"],
      "stack": ["FlutterFlow"],
      "period": "2023",
      "links": { 
      },
      "emoji": "üîç",
      "images": ["/projects/Shuffle-1.png", "/projects/Shuffle-2.png", "/projects/Shuffle-3.png"]
    }

  ]
}